{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_with_RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmendonca28/DLNID/blob/master/RNN_with_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIwoxFN7oaMM",
        "colab_type": "code",
        "outputId": "26319305-fc5d-484b-af0f-233c4dd535a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhmniNfUpakt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pdb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split\n",
        "from statistics import mean\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14N-fOKApHYf",
        "colab_type": "code",
        "outputId": "997f64fc-4dc0-4907-dadb-1edad57bdd74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_data = pd.read_csv(\"drive/My Drive/Masters/Project/DLNID/Datasets/KDDTrainRenameNominalValuesNormalizedOHE.csv\", header=0, low_memory=False, dtype = np.float32)\n",
        "test_data = pd.read_csv(\"drive/My Drive/Masters/Project/DLNID/Datasets/KDDTestRenameNominalValuesNormalizedOHE.csv\", header=0, low_memory=False, dtype = np.float32)\n",
        "test21_data = pd.read_csv(\"drive/My Drive/Masters/Project/DLNID/Datasets/KDDTest-21RenameNominalValuesNormalizedOHE.csv\", header=0, low_memory=False, dtype = np.float32)\n",
        "print(len(train_data))\n",
        "print(len(test_data))\n",
        "print(len(test21_data))\n",
        "print(test_data)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "125973\n",
            "22544\n",
            "11850\n",
            "       duration  protocol_type=1  ...  dst_host_srv_rerror_rate  class\n",
            "0      0.000000              1.0  ...                      1.00    1.0\n",
            "1      0.000000              1.0  ...                      1.00    1.0\n",
            "2      0.000035              1.0  ...                      0.00    0.0\n",
            "3      0.000000              0.0  ...                      0.00    1.0\n",
            "4      0.000017              1.0  ...                      0.71    1.0\n",
            "5      0.000000              1.0  ...                      0.00    0.0\n",
            "6      0.000000              1.0  ...                      0.04    0.0\n",
            "7      0.000000              1.0  ...                      0.02    1.0\n",
            "8      0.000000              1.0  ...                      0.00    0.0\n",
            "9      0.000000              1.0  ...                      0.00    1.0\n",
            "10     0.000000              1.0  ...                      0.32    1.0\n",
            "11     0.000000              1.0  ...                      0.00    0.0\n",
            "12     0.000000              1.0  ...                      1.00    1.0\n",
            "13     0.000000              1.0  ...                      0.00    1.0\n",
            "14     0.000641              1.0  ...                      0.07    0.0\n",
            "15     0.000000              1.0  ...                      0.00    0.0\n",
            "16     0.000000              1.0  ...                      0.00    0.0\n",
            "17     0.000000              1.0  ...                      0.00    0.0\n",
            "18     0.000000              0.0  ...                      0.00    0.0\n",
            "19     0.000000              1.0  ...                      1.00    1.0\n",
            "20     0.000000              1.0  ...                      1.00    1.0\n",
            "21     0.000000              1.0  ...                      0.00    1.0\n",
            "22     0.000000              1.0  ...                      0.00    0.0\n",
            "23     0.000000              1.0  ...                      0.00    0.0\n",
            "24     0.000000              1.0  ...                      1.00    1.0\n",
            "25     0.000000              1.0  ...                      1.00    1.0\n",
            "26     0.000000              1.0  ...                      0.00    0.0\n",
            "27     0.000000              1.0  ...                      0.00    0.0\n",
            "28     0.000000              0.0  ...                      0.00    1.0\n",
            "29     0.000000              0.0  ...                      0.00    0.0\n",
            "...         ...              ...  ...                       ...    ...\n",
            "22514  0.000000              0.0  ...                      0.00    0.0\n",
            "22515  0.000000              1.0  ...                      0.41    1.0\n",
            "22516  0.000000              1.0  ...                      0.00    0.0\n",
            "22517  0.129914              1.0  ...                      0.01    1.0\n",
            "22518  0.000000              1.0  ...                      0.00    0.0\n",
            "22519  0.142233              1.0  ...                      0.00    1.0\n",
            "22520  0.000000              1.0  ...                      1.00    1.0\n",
            "22521  0.000000              0.0  ...                      0.00    1.0\n",
            "22522  0.000000              1.0  ...                      0.05    1.0\n",
            "22523  0.000000              1.0  ...                      0.00    0.0\n",
            "22524  0.000260              1.0  ...                      0.00    1.0\n",
            "22525  0.035762              1.0  ...                      0.57    1.0\n",
            "22526  0.000000              1.0  ...                      0.00    0.0\n",
            "22527  0.000000              1.0  ...                      0.00    0.0\n",
            "22528  0.000000              0.0  ...                      0.00    1.0\n",
            "22529  0.000000              1.0  ...                      0.00    0.0\n",
            "22530  0.000000              1.0  ...                      0.71    1.0\n",
            "22531  0.000000              1.0  ...                      0.00    1.0\n",
            "22532  0.000000              1.0  ...                      0.00    0.0\n",
            "22533  0.000000              1.0  ...                      0.00    0.0\n",
            "22534  0.000000              1.0  ...                      1.00    1.0\n",
            "22535  0.000000              1.0  ...                      0.00    0.0\n",
            "22536  0.000000              1.0  ...                      1.00    1.0\n",
            "22537  0.000017              1.0  ...                      0.00    1.0\n",
            "22538  0.000000              0.0  ...                      0.00    1.0\n",
            "22539  0.000000              1.0  ...                      0.00    0.0\n",
            "22540  0.000000              1.0  ...                      0.00    0.0\n",
            "22541  0.000000              1.0  ...                      0.07    1.0\n",
            "22542  0.000000              0.0  ...                      0.00    0.0\n",
            "22543  0.000000              1.0  ...                      1.00    1.0\n",
            "\n",
            "[22544 rows x 123 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayQwA9kgqBho",
        "colab_type": "code",
        "outputId": "bba0d495-b8de-46c2-8984-e05f23b87e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "targets_pd = train_data.iloc[0:, 122]\n",
        "features_pd = train_data.iloc[0:, 0:122]\n",
        "\n",
        "test_targets_pd = test_data.iloc[0:, 122]\n",
        "test_features_pd = test_data.iloc[0:, 0:122]\n",
        "\n",
        "test21_targets_pd = test21_data.iloc[0:, 122]\n",
        "test21_features_pd = test21_data.iloc[0:, 0:122]\n",
        "\n",
        "# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
        "featuresTrain = torch.FloatTensor(features_pd.values)\n",
        "targetsTrain = torch.LongTensor(targets_pd.values)\n",
        "\n",
        "featuresTest = torch.FloatTensor(test_features_pd.values)\n",
        "targetsTest = torch.LongTensor(test_targets_pd.values)\n",
        "\n",
        "featuresTest21 = torch.FloatTensor(test21_features_pd.values)\n",
        "targetsTest21 = torch.LongTensor(test21_targets_pd.values)\n",
        "\n",
        "# batch_size and epoch\n",
        "batch_size = 1000\n",
        "num_epochs = 100\n",
        "\n",
        "# Pytorch train and test sets\n",
        "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
        "test = torch.utils.data.TensorDataset(featuresTest, targetsTest)\n",
        "test21 = torch.utils.data.TensorDataset(featuresTest21, targetsTest21)\n",
        "\n",
        "# data loader\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = True, drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False, drop_last=True)\n",
        "test21_loader = torch.utils.data.DataLoader(test21, batch_size = batch_size, shuffle = False, drop_last=True)\n",
        "print(len(train))\n",
        "print(featuresTrain.size())\n",
        "print(targetsTrain.size())\n",
        "print(featuresTest.size())\n",
        "print(targetsTest.size())\n",
        "print(featuresTest21.size())\n",
        "print(targetsTest21.size())\n",
        "print(len(test))\n",
        "print(len(train_loader))\n",
        "print(len(test_loader))\n",
        "print(len(test21_loader))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "125973\n",
            "torch.Size([125973, 122])\n",
            "torch.Size([125973])\n",
            "torch.Size([22544, 122])\n",
            "torch.Size([22544])\n",
            "torch.Size([11850, 122])\n",
            "torch.Size([11850])\n",
            "22544\n",
            "125\n",
            "22\n",
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qO8lBh4rS_t",
        "colab_type": "code",
        "outputId": "776d423e-0bde-45e1-f718-276dc6041bde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import argparse\n",
        "parser = argparse.ArgumentParser(description='Network Intrusion Classifier')\n",
        "parser.add_argument('--lr', action='store', type=float, help='use different versions of network', default=1e-1)\n",
        "parser.add_argument('--epochs', action='store', type=int, help='use different versions of network', default=num_epochs)\n",
        "opts = parser.parse_args('')\n",
        "print(opts)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(epochs=100, lr=0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVJ35CyGrxLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the RNN Model\n",
        "class RNNModel(nn.Module):\n",
        "  def __init__(self ):\n",
        "    super(RNNModel, self).__init__()\n",
        "    self.rnn = nn.RNN(122, 80, 1, batch_first=True, nonlinearity='relu')\n",
        "    self.fc = nn.Linear(80, 2)\n",
        "    self.layer_dim = 1\n",
        "    self.hidden_dim = 80\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
        "    out, hn = self.rnn(x, h0.detach())\n",
        "    out = self.fc(out[:, -1, :])\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc_Bui2xtk7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_network_performance(predictions, truth):\n",
        "  # given a list with predicted and correct values\n",
        "  # calculate precision, recall and f-score\n",
        "  cm = get_confusion_matrix(predictions, truth)\n",
        "  TP = cm[0][0]\n",
        "  FP = cm[0][1]\n",
        "  FN = cm[1][0]\n",
        "  TN = cm[1][1]\n",
        "\n",
        "  precision = TP/(TP+FP)\n",
        "  recall = TP/(TP+FN)\n",
        "  classification_accuracy = (TP+TN) / (TP + TN + FP + FN)\n",
        "  f_score = 2 * ((precision*recall)/(precision + recall))\n",
        "\n",
        "  return precision, recall, f_score, classification_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bR26jJ3uzmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_confusion_matrix(preds, truth):\n",
        "    preds = torch.stack(preds).flatten()\n",
        "    truth = torch.stack(truth).flatten()\n",
        "    K = len(np.unique(truth)) # Number of classes\n",
        "    result = np.zeros((K, K))\n",
        "    for i in range(len(truth)):\n",
        "        result[preds[i]][truth[i]] += 1\n",
        "    confusion_matrix = result\n",
        "    return confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgQtc5iM0mZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_network(model, test_set, targets):\n",
        "  # given a dataset and network, compute accuracy\n",
        "  \n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  \n",
        "  test_loss = 0\n",
        "  predictions = []\n",
        "  labels = []\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for i, (images, label) in enumerate(test_set):\n",
        "      model.eval()\n",
        "      \n",
        "      images = Variable(images.view(-1, 1, 122))\n",
        "      output = model(images)\n",
        "      predicted_index = torch.max(output.data, 1)[1]\n",
        "      predictions.append(predicted_index)\n",
        "      labels.append(label)\n",
        "      \n",
        "      test_loss = criterion(output, label).item()\n",
        "    precision, recall, f_score, classification_accuracy = evaluate_network_performance(predictions, labels)\n",
        "\n",
        "  return precision, recall, f_score, classification_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTJepeHCu2u0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_network(model, train_dataset, test_dataset):\n",
        "  optimizer = optim.Adam(model.parameters(), lr=opts.lr)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  \n",
        "  num_training_epochs = opts.epochs\n",
        "  \n",
        "  for e in range(num_training_epochs):\n",
        "    print(\"Running Epoch: \", e, \" ....\")\n",
        "    running_loss = 0\n",
        "    \n",
        "    for i,(images, labels) in enumerate(train_dataset):\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "      labels = Variable(labels)\n",
        "      images = Variable(images.view(-1, 1, 122))  \n",
        "  \n",
        "      output = model(images)\n",
        "      loss = criterion(output, labels)\n",
        "      \n",
        "      running_loss += loss.item()\n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "    epoch_loss = running_loss/(len(train_dataset))\n",
        "    \n",
        "    print('Iteration ', e, 'loss ', epoch_loss)\n",
        "    print('          PREC | REC | F1 | ACC')\n",
        "    precision, recall, f_score, classification_accuracy = test_network(model, train_dataset, targetsTrain)\n",
        "    print('test set',\"{0:.2f} | \".format(precision),\"{0:.2f} | \".format(recall),\"{0:.2f} | \".format(f_score),\"{0:.2f}\".format(classification_accuracy))\n",
        "\n",
        "    precision, recall, f_score, classification_accuracy = test_network(model, test_dataset, targetsTest)\n",
        "    print('train set',\"{0:.2f} | \".format(precision),\"{0:.2f} | \".format(recall),\"{0:.2f} | \".format(f_score),\"{0:.2f}\".format(classification_accuracy))\n",
        "    print()\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULTQgudGwC1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  model = RNNModel()\n",
        "  print(model)\n",
        "  print('Started training network......')\n",
        "  model = train_network(model, train_loader, test_loader)\n",
        "  \n",
        "  print('Final Testing.......')\n",
        "  precision, recall, f_score, classification_accuracy = test_network(model, test_loader, targetsTest)\n",
        "  print('test set',\"{0:.2f}\".format(precision),\"{0:.2f}\".format(recall),\"{0:.2f}\".format(f_score),\"{0:.2f}\".format(classification_accuracy))\n",
        "  print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddLXU18t7RWk",
        "colab_type": "code",
        "outputId": "291dc5bd-7418-4573-829c-d5a00207b8f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNNModel(\n",
            "  (rnn): RNN(122, 80, batch_first=True)\n",
            "  (fc): Linear(in_features=80, out_features=2, bias=True)\n",
            ")\n",
            "Started training network......\n",
            "Running Epoch:  0  ....\n",
            "Iteration  0 loss  0.10034591399133205\n",
            "          PREC | REC | F1 | ACC\n",
            "test set   0.99 |  0.98 |  0.98 |  0.98\n",
            "train set 0.66 |  0.92 |  0.77 |  0.77\n",
            "\n",
            "Running Epoch:  1  ....\n",
            "Iteration  1 loss  0.037485645949840544\n",
            "          PREC | REC | F1 | ACC\n",
            "test set   0.99 |  0.99 |  0.99 |  0.99\n",
            "train set 0.69 |  0.92 |  0.79 |  0.78\n",
            "\n",
            "Running Epoch:  2  ....\n",
            "Iteration  2 loss  0.028136018231511115\n",
            "          PREC | REC | F1 | ACC\n",
            "test set   0.98 |  1.00 |  0.99 |  0.99\n",
            "train set 0.68 |  0.97 |  0.80 |  0.79\n",
            "\n",
            "Running Epoch:  3  ....\n",
            "Iteration  3 loss  0.02232839171588421\n",
            "          PREC | REC | F1 | ACC\n",
            "test set   0.99 |  0.99 |  0.99 |  0.99\n",
            "train set 0.68 |  0.97 |  0.80 |  0.79\n",
            "\n",
            "Running Epoch:  4  ....\n",
            "Iteration  4 loss  0.020518202863633633\n",
            "          PREC | REC | F1 | ACC\n",
            "test set   0.99 |  0.99 |  0.99 |  0.99\n",
            "train set 0.69 |  0.96 |  0.81 |  0.80\n",
            "\n",
            "Running Epoch:  5  ....\n",
            "Iteration  5 loss  0.020066096175462008\n",
            "          PREC | REC | F1 | ACC\n",
            "test set   0.99 |  0.99 |  0.99 |  0.99\n",
            "train set 0.69 |  0.96 |  0.81 |  0.80\n",
            "\n",
            "Running Epoch:  6  ....\n",
            "Iteration  6 loss  0.01879789598658681\n",
            "          PREC | REC | F1 | ACC\n",
            "test set   0.99 |  0.99 |  0.99 |  0.99\n",
            "train set 0.70 |  0.96 |  0.81 |  0.81\n",
            "\n",
            "Running Epoch:  7  ....\n",
            "Iteration  7 loss  0.01871979702450335\n",
            "          PREC | REC | F1 | ACC\n",
            "test set   1.00 |  0.99 |  0.99 |  0.99\n",
            "train set 0.71 |  0.96 |  0.82 |  0.82\n",
            "\n",
            "Running Epoch:  8  ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-bb4fc53f4719>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Started training network......'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Final Testing.......'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-222b75980d28>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(model, train_dataset, test_dataset)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}