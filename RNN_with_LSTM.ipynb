{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_with_LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmendonca28/DLNID/blob/master/RNN_with_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIwoxFN7oaMM",
        "colab_type": "code",
        "outputId": "72415a8f-4b60-4f9b-dbda-266499fb4445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhmniNfUpakt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pdb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split\n",
        "from statistics import mean\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14N-fOKApHYf",
        "colab_type": "code",
        "outputId": "d6dc27b4-eeeb-4ca0-a28d-eaad4bdb0cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_data = pd.read_csv(\"drive/My Drive/Masters/Project/DLNID/Datasets/KDDTrainRenameNominalValuesNormalized.csv\", header=0, low_memory=False, dtype = np.float32)\n",
        "test_data = pd.read_csv(\"drive/My Drive/Masters/Project/DLNID/Datasets/KDDTestRenameNominalValuesNormalized.csv\", header=0, low_memory=False, dtype = np.float32)\n",
        "print(len(train_data))\n",
        "print(len(test_data))\n",
        "print(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "125973\n",
            "22544\n",
            "       duration  protocol_type  ...  dst_host_srv_rerror_rate  class\n",
            "0      0.000000            1.0  ...                      1.00    1.0\n",
            "1      0.000000            1.0  ...                      1.00    1.0\n",
            "2      0.000035            1.0  ...                      0.00    0.0\n",
            "3      0.000000            3.0  ...                      0.00    1.0\n",
            "4      0.000017            1.0  ...                      0.71    1.0\n",
            "5      0.000000            1.0  ...                      0.00    0.0\n",
            "6      0.000000            1.0  ...                      0.04    0.0\n",
            "7      0.000000            1.0  ...                      0.02    1.0\n",
            "8      0.000000            1.0  ...                      0.00    0.0\n",
            "9      0.000000            1.0  ...                      0.00    1.0\n",
            "10     0.000000            1.0  ...                      0.32    1.0\n",
            "11     0.000000            1.0  ...                      0.00    0.0\n",
            "12     0.000000            1.0  ...                      1.00    1.0\n",
            "13     0.000000            1.0  ...                      0.00    1.0\n",
            "14     0.000641            1.0  ...                      0.07    0.0\n",
            "15     0.000000            1.0  ...                      0.00    0.0\n",
            "16     0.000000            1.0  ...                      0.00    0.0\n",
            "17     0.000000            1.0  ...                      0.00    0.0\n",
            "18     0.000000            2.0  ...                      0.00    0.0\n",
            "19     0.000000            1.0  ...                      1.00    1.0\n",
            "20     0.000000            1.0  ...                      1.00    1.0\n",
            "21     0.000000            1.0  ...                      0.00    1.0\n",
            "22     0.000000            1.0  ...                      0.00    0.0\n",
            "23     0.000000            1.0  ...                      0.00    0.0\n",
            "24     0.000000            1.0  ...                      1.00    1.0\n",
            "25     0.000000            1.0  ...                      1.00    1.0\n",
            "26     0.000000            1.0  ...                      0.00    0.0\n",
            "27     0.000000            1.0  ...                      0.00    0.0\n",
            "28     0.000000            3.0  ...                      0.00    1.0\n",
            "29     0.000000            2.0  ...                      0.00    0.0\n",
            "...         ...            ...  ...                       ...    ...\n",
            "22514  0.000000            2.0  ...                      0.00    0.0\n",
            "22515  0.000000            1.0  ...                      0.41    1.0\n",
            "22516  0.000000            1.0  ...                      0.00    0.0\n",
            "22517  0.129914            1.0  ...                      0.01    1.0\n",
            "22518  0.000000            1.0  ...                      0.00    0.0\n",
            "22519  0.142233            1.0  ...                      0.00    1.0\n",
            "22520  0.000000            1.0  ...                      1.00    1.0\n",
            "22521  0.000000            2.0  ...                      0.00    1.0\n",
            "22522  0.000000            1.0  ...                      0.05    1.0\n",
            "22523  0.000000            1.0  ...                      0.00    0.0\n",
            "22524  0.000260            1.0  ...                      0.00    1.0\n",
            "22525  0.035762            1.0  ...                      0.57    1.0\n",
            "22526  0.000000            1.0  ...                      0.00    0.0\n",
            "22527  0.000000            1.0  ...                      0.00    0.0\n",
            "22528  0.000000            3.0  ...                      0.00    1.0\n",
            "22529  0.000000            1.0  ...                      0.00    0.0\n",
            "22530  0.000000            1.0  ...                      0.71    1.0\n",
            "22531  0.000000            1.0  ...                      0.00    1.0\n",
            "22532  0.000000            1.0  ...                      0.00    0.0\n",
            "22533  0.000000            1.0  ...                      0.00    0.0\n",
            "22534  0.000000            1.0  ...                      1.00    1.0\n",
            "22535  0.000000            1.0  ...                      0.00    0.0\n",
            "22536  0.000000            1.0  ...                      1.00    1.0\n",
            "22537  0.000017            1.0  ...                      0.00    1.0\n",
            "22538  0.000000            3.0  ...                      0.00    1.0\n",
            "22539  0.000000            1.0  ...                      0.00    0.0\n",
            "22540  0.000000            1.0  ...                      0.00    0.0\n",
            "22541  0.000000            1.0  ...                      0.07    1.0\n",
            "22542  0.000000            2.0  ...                      0.00    0.0\n",
            "22543  0.000000            1.0  ...                      1.00    1.0\n",
            "\n",
            "[22544 rows x 42 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayQwA9kgqBho",
        "colab_type": "code",
        "outputId": "72742688-d164-4cf3-990f-0e28bbc0eeea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "targets_pd = train_data.iloc[0:, 41]\n",
        "features_pd = train_data.iloc[0:, 0:41]\n",
        "\n",
        "test_targets_pd = test_data.iloc[0:, 41]\n",
        "test_features_pd = test_data.iloc[0:, 0:41]\n",
        "\n",
        "# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
        "featuresTrain = torch.FloatTensor(features_pd.values)\n",
        "# torch_tensor = torch.tensor(targets_df['targets'].values)\n",
        "targetsTrain = torch.LongTensor(targets_pd.values)\n",
        "\n",
        "featuresTest = torch.FloatTensor(test_features_pd.values)\n",
        "# torch_tensor = torch.tensor(targets_df['targets'].values)\n",
        "targetsTest = torch.LongTensor(test_targets_pd.values)\n",
        "\n",
        "# batch_size and epoch\n",
        "batch_size = 1\n",
        "# n_iters = 10000\n",
        "num_epochs = 10\n",
        "\n",
        "# Pytorch train and test sets\n",
        "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
        "test = torch.utils.data.TensorDataset(featuresTest, targetsTest)\n",
        "\n",
        "# data loader\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)\n",
        "print(len(train))\n",
        "print(len(test))\n",
        "print(len(train_loader))\n",
        "print(len(test_loader))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "125973\n",
            "22544\n",
            "125973\n",
            "22544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qO8lBh4rS_t",
        "colab_type": "code",
        "outputId": "3f162407-72bc-47d0-8dbc-d8723f774fcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import argparse\n",
        "parser = argparse.ArgumentParser(description='Network Intrusion Classifier')\n",
        "parser.add_argument('--lr', action='store', type=float, help='use different versions of network', default=1e-1)\n",
        "parser.add_argument('--epochs', action='store', type=int, help='use different versions of network', default=num_epochs)\n",
        "opts = parser.parse_args('')\n",
        "print(opts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(epochs=10, lr=0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVJ35CyGrxLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the RNN Model\n",
        "class RNNModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(RNNModel, self).__init__()\n",
        "    self.rnn = nn.LSTM(41, 80, 1)\n",
        "    self.out = nn.Linear(80, 2)\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, x.shape[0], x.shape[1])\n",
        "    out, (h_n, h_c) = self.rnn(x, None)\n",
        "    out = self.out(out[-1, :, :])\n",
        "    out = F.relu(out)\n",
        "    out = self.dropout(out)\n",
        "    out = torch.sigmoid(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc_Bui2xtk7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_network_performance(predictions, truth):\n",
        "  # given a list with predicted and correct values\n",
        "  # calculate precision, recall and f-score\n",
        "#   pdb.set_trace()\n",
        "  cm = get_confusion_matrix(predictions, truth)\n",
        "  TP = cm[0][0]\n",
        "  FP = cm[0][1]\n",
        "  FN = cm[1][0]\n",
        "  TN = cm[1][1]\n",
        "\n",
        "  precision = TP/(TP+FP)\n",
        "  recall = TP/(TP+FN)\n",
        "  classification_accuracy = (TP+TN) / (TP + TN + FP + FN)\n",
        "  f_score = 2 * ((precision*recall)/(precision + recall))\n",
        "\n",
        "  return precision, recall, f_score, classification_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bR26jJ3uzmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_confusion_matrix(preds, truth):\n",
        "    K = len(np.unique(truth)) # Number of classes\n",
        "    result = np.zeros((K, K))\n",
        "    for i in range(len(truth)):\n",
        "        result[preds[i]][truth[i]] += 1\n",
        "    confusion_matrix = result\n",
        "    return confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgQtc5iM0mZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_network(model, test_set, targets):\n",
        "  # given a dataset and network, compute accuracy\n",
        "  \n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  \n",
        "  labels = targets.tolist()\n",
        "  \n",
        "  test_loss = 0\n",
        "  predictions = []\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for i, (images, label) in enumerate(test_set):\n",
        "      model.eval()\n",
        "      \n",
        "#       images, labels = images.to(device), labels.to(device)\n",
        "      output = model(images)\n",
        "      predicted_index = torch.max(output.data, 1)[1]\n",
        "      predictions.append(predicted_index.item())\n",
        "#       labels.append(label.item())\n",
        "      \n",
        "      test_loss = criterion(output, label).item()\n",
        "    \n",
        "    precision, recall, f_score, classification_accuracy = evaluate_network_performance(predictions, labels)\n",
        "\n",
        "  return precision, recall, f_score, classification_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTJepeHCu2u0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_network(model, train_dataset):\n",
        "  optimizer = optim.Adam(model.parameters(), lr=opts.lr)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  \n",
        "  num_training_epochs = opts.epochs\n",
        "  \n",
        "  for e in range(num_training_epochs):\n",
        "    print(\"Running Epoch: \", e, \" ....\")\n",
        "    running_loss = 0\n",
        "    \n",
        "    for i,(images, labels) in enumerate(train_dataset):\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "#       images, labels = images.to(device), labels.to(device)\n",
        "      \n",
        "      output = model(images)\n",
        "      loss = criterion(output, labels)\n",
        "      \n",
        "      running_loss += loss.item()\n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "    epoch_loss = running_loss/(len(train_dataset))\n",
        "    \n",
        "    print('Iteration ', e, 'loss ', epoch_loss)\n",
        "    print('          PREC | REC | F1  |   ACC')\n",
        "#     precision, recall, f_score, classification_accuracy = test_network(model, test_loader, targetsTest)\n",
        "#     print('val set  ',\"{0:.2f} | \".format(precision),\"{0:.2f} | \".format(recall),\"{0:.2f} | \".format(f_score),\"{0:.2f}\".format(classification_accuracy))\n",
        "\n",
        "    precision, recall, f_score, classification_accuracy = test_network(model, train_dataset, targetsTrain)\n",
        "    print('train set',\"{0:.2f} | \".format(precision),\"{0:.2f} | \".format(recall),\"{0:.2f} | \".format(f_score),\"{0:.2f}\".format(classification_accuracy))\n",
        "    print()\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULTQgudGwC1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  model = RNNModel()\n",
        "  print(model)\n",
        "#   model.to(device)\n",
        "  print('Started training network......')\n",
        "  model = train_network(model, train_loader)\n",
        "  \n",
        "  print('Started testing network.......')\n",
        "  precision, recall, f_score, classification_accuracy = test_network(model, test_loader, targetsTest)\n",
        "  print('test set',\"{0:.2f}\".format(precision),\"{0:.2f}\".format(recall),\"{0:.2f}\".format(f_score),\"{0:.2f}\".format(classification_accuracy))\n",
        "  print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddLXU18t7RWk",
        "colab_type": "code",
        "outputId": "be8765cc-7277-40dd-edf8-876590a8fcf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNNModel(\n",
            "  (rnn): LSTM(41, 80)\n",
            "  (out): Linear(in_features=80, out_features=2, bias=True)\n",
            "  (dropout): Dropout(p=0.5)\n",
            ")\n",
            "Started training network......\n",
            "Running Epoch:  0  ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-04d797e45ad2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#   model.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Started training network......'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Started testing network.......'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-196170758f04>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(model, train_dataset)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}